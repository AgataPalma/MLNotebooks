{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c76f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1697414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook started at: 2025-01-20 08:24:30.127569\n"
     ]
    }
   ],
   "source": [
    "notebook_start_time = datetime.now()\n",
    "print(f\"Notebook started at: {notebook_start_time}\")\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv('complete_decimal_dataset.csv')\n",
    "\n",
    "#Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['specific_class_encoded'] = label_encoder.fit_transform(df['specific_class'])\n",
    "\n",
    "#Prepare features and target\n",
    "X = df.drop(columns=['label', 'category', 'specific_class', 'specific_class_encoded'])\n",
    "y = df['specific_class_encoded']\n",
    "\n",
    "#Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1330e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing sets Splits (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def optimize_logistic_regression(trial):\n",
    "    \n",
    "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs'])\n",
    "\n",
    "    #l1_ratio if elasticnet is selected\n",
    "    l1_ratio = None\n",
    "    if penalty == 'elasticnet':\n",
    "        if solver != 'saga':  # Elasticnet only works with saga solver\n",
    "            raise optuna.TrialPruned()\n",
    "        l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "\n",
    "    #compatibility between penalty and solver\n",
    "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "        raise optuna.TrialPruned()\n",
    "    if penalty == 'l2' and solver not in ['lbfgs', 'liblinear', 'saga']:\n",
    "        raise optuna.TrialPruned()\n",
    "\n",
    "    #Logistic Regression model\n",
    "    model = LogisticRegression(\n",
    "        C=C, penalty=penalty, solver=solver, random_state=42, max_iter=1000, l1_ratio=l1_ratio\n",
    "    )\n",
    "\n",
    "    #Cross-validation\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scorer = make_scorer(f1_score, average='macro')\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=stratified_kfold, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1096327-160d-4dad-9364-2a02bcbf7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-20 08:24:31,745] A new study created in memory with name: no-name-ce38b78e-e364-4d1c-8fc9-a6709abb9d2c\n",
      "[I 2025-01-20 08:24:31,751] Trial 1 pruned. \n",
      "[I 2025-01-20 08:24:31,770] Trial 8 pruned. \n",
      "[I 2025-01-20 08:26:08,371] Trial 0 finished with value: 0.20671388102931956 and parameters: {'C': 0.00013104504885704289, 'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.057622501421336514}. Best is trial 0 with value: 0.20671388102931956.\n",
      "[I 2025-01-20 08:27:25,924] Trial 6 finished with value: 0.20669709721325907 and parameters: {'C': 0.0003877552880547607, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 0 with value: 0.20671388102931956.\n",
      "[I 2025-01-20 08:27:48,852] Trial 7 finished with value: 0.6555050642700521 and parameters: {'C': 0.001196162324265911, 'penalty': 'l2', 'solver': 'lbfgs'}. Best is trial 7 with value: 0.6555050642700521.\n",
      "[I 2025-01-20 08:28:46,977] Trial 4 finished with value: 0.8354180888797542 and parameters: {'C': 0.3552017555114897, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 4 with value: 0.8354180888797542.\n",
      "[I 2025-01-20 08:31:28,213] Trial 2 finished with value: 0.8593539535769287 and parameters: {'C': 0.0058821111137577365, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.8593539535769287.\n",
      "[I 2025-01-20 08:31:32,617] Trial 5 finished with value: 0.858882350908915 and parameters: {'C': 0.1457611877724019, 'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.8988082480913813}. Best is trial 2 with value: 0.8593539535769287.\n",
      "[I 2025-01-20 08:42:05,560] Trial 3 finished with value: 0.8778235134186254 and parameters: {'C': 3.1678264009993544, 'penalty': 'elasticnet', 'solver': 'saga', 'l1_ratio': 0.4122565778860381}. Best is trial 3 with value: 0.8778235134186254.\n",
      "[I 2025-01-20 08:53:37,176] Trial 9 finished with value: 0.8804899537187021 and parameters: {'C': 0.438732755172357, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 9 with value: 0.8804899537187021.\n"
     ]
    }
   ],
   "source": [
    "#Optuna study\n",
    "study_lr = optuna.create_study(direction=\"maximize\")\n",
    "study_lr.optimize(optimize_logistic_regression, n_trials=10, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b83a90f-1293-40d1-9355-0c5b53681e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'C': 0.438732755172357, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters for Random Forest: {study_lr.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d120ee1-9d32-4eb8-87f9-e3cf5b3e3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameters\n",
    "best_params = study_lr.best_params\n",
    "model = LogisticRegression(**best_params, random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a10525-39c0-42d5-a5d5-66215cff46e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time: 1116.33 seconds\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    244790\n",
      "           1       1.00      1.00      1.00     15021\n",
      "           2       1.00      1.00      1.00      1974\n",
      "           3       0.92      0.18      0.31     10902\n",
      "           4       1.00      1.00      1.00      4968\n",
      "           5       1.00      1.00      1.00      3989\n",
      "\n",
      "    accuracy                           0.97    281644\n",
      "   macro avg       0.98      0.86      0.88    281644\n",
      "weighted avg       0.97      0.97      0.96    281644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Model training time: {training_duration:.2f} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Classification report on test data\n",
    "print(\"Classification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d2ae6b-609c-45a4-89ea-9ebc0239b704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ended at: 2025-01-20 09:12:13.849884\n",
      "Total notebook runtime: 0:47:43.722315\n"
     ]
    }
   ],
   "source": [
    "# Log the end time\n",
    "notebook_end_time = datetime.now()\n",
    "print(f\"Notebook ended at: {notebook_end_time}\")\n",
    "\n",
    "# Calculate the total duration\n",
    "notebook_duration = notebook_end_time - notebook_start_time\n",
    "print(f\"Total notebook runtime: {notebook_duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f09cac1-f2e8-4883-b365-f063bf65ee9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.97, Test Accuracy: 0.97\n",
      "Training F1 Score: 0.88, Test F1 Score: 0.88\n",
      "Test set performs better than training.\n",
      "\n",
      "Classification Report (Training):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    978947\n",
      "           1       1.00      1.00      1.00     59642\n",
      "           2       1.00      1.00      1.00      8017\n",
      "           3       0.92      0.18      0.30     43998\n",
      "           4       1.00      1.00      1.00     19983\n",
      "           5       1.00      1.00      1.00     15988\n",
      "\n",
      "    accuracy                           0.97   1126575\n",
      "   macro avg       0.98      0.86      0.88   1126575\n",
      "weighted avg       0.97      0.97      0.96   1126575\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    244790\n",
      "           1       1.00      1.00      1.00     15021\n",
      "           2       1.00      1.00      1.00      1974\n",
      "           3       0.92      0.18      0.31     10902\n",
      "           4       1.00      1.00      1.00      4968\n",
      "           5       1.00      1.00      1.00      3989\n",
      "\n",
      "    accuracy                           0.97    281644\n",
      "   macro avg       0.98      0.86      0.88    281644\n",
      "weighted avg       0.97      0.97      0.96    281644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score, make_scorer, precision_score, recall_score, f1_score\n",
    "\n",
    "#Evaluate on training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "\n",
    "#Evaluate on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "#Compare results\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}, Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Training F1 Score: {train_f1:.2f}, Test F1 Score: {test_f1:.2f}\")\n",
    "\n",
    "if train_accuracy > test_accuracy:\n",
    "    print(\"The model might be overfitting.\")\n",
    "elif train_accuracy < test_accuracy:\n",
    "    print(\"Test set performs better than training.\")\n",
    "else:\n",
    "    print(\"Training and test performance are comparable.\")\n",
    "\n",
    "#Classification reports\n",
    "print(\"\\nClassification Report (Training):\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054ccf6-e3bb-49a9-b4bb-05cf3e8cf615",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
